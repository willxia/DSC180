{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22bd9bc79fdb478693cb51fa9eb5e3ba",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Categorizing Memo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c1f66bb69f684733930431fbc9472282",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Imports and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "c048d529bd51487090d0d360c9b9b11c",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:39:37.137570: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-05 22:39:37.186661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "cd0f577f1c1945e088e786f75932a671",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "06eec58d1d6d4200b27681b5c3a97f5d",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "4a1562ab261443b2b0dec942768981bf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Transacation_outflows_3k.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "238b2222ac454d12a20604a4f8dbc4b8",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We only keep the most important 9 categories since other categories have a relatively low frequency. At this point, we will prioritize the data with the 9 categories below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "26201b1564f54715a0e642fc39524b98",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_description\n",
       "GENERAL_MERCHANDISE    516039\n",
       "FOOD_AND_BEVERAGES     467667\n",
       "GROCERIES              220227\n",
       "TRAVEL                  59555\n",
       "PETS                     8539\n",
       "EDUCATION                3895\n",
       "RENT                     3453\n",
       "OVERDRAFT                3324\n",
       "MORTGAGE                 1047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"category_description\"] != df['memo_clean']]\n",
    "df = df.reset_index(drop=True)\n",
    "df['category_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "34db710fe7e745fcba76afa709296526",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3c901d8f65a649129b5d8cd5ade08a80",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Lowercase and Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "eff28f133aa449e8b38f3917964eac23",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#lowercase all\n",
    "df['memo_clean'] = df['memo_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "3c92f5bcf81a4e559b593f920881c871",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "def remove_stop(df):\n",
    "\n",
    "        #remove stopwords in the list\n",
    "        df['memo_clean'] = df['memo_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "remove_stop(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b857a99330f64043b42dc18772cc6704",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "8f9ff166ace8427897b466d51eddaf9d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "df['memo_clean'] = df['memo_clean'].str.strip()\n",
    "\n",
    "punctuation_to_keep = {'-', \"'\"}\n",
    "punctuation_to_remove = ''.join(set(string.punctuation) - punctuation_to_keep)\n",
    "\n",
    "# Escape punctuation characters that need to be escaped\n",
    "punctuation_to_remove = re.escape(punctuation_to_remove)\n",
    "\n",
    "# Remove specified punctuation and handle '-'\n",
    "df['memo_clean'] = df['memo_clean'].str.replace(f'[{punctuation_to_remove}-]', '', regex=True)\n",
    "\n",
    "# Replace underscores with spaces\n",
    "df['memo_clean'] = df['memo_clean'].str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4982aa940b9e4183a0d16ed1daf02e4b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Since there is censored personal information in the transaction code, we will remove all XXXX in the memo_clean data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "7cc2b20ff50c4e138ad926fcd8505ed8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# alphabet set\n",
    "\n",
    "alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "def process_memo(memo):\n",
    "    splits = memo.split(' ')\n",
    "    results = [s for s in splits if not alphabet.intersection(set(s)) == set('x') and s not in ['dates', 'date'] and s.count('x') < 3]\n",
    "    return ' '.join(results)\n",
    "\n",
    "df['memo_clean'] = df['memo_clean'].apply(process_memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "5048655d37d649a9919163cd24c21a93",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "df = df.sample(50_000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6ec4dbf4773a48408ff15fc6d38647ea",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Train, Validation, and Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "56182122f1fe467b98734555c7e5b256",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We split the data into training, validation, and test data. To ensure that they all have a similar proportion of each category, we will enable Stratify in the train_test_split function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "967ea4053f314643ba7d444a23bc3089",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "X = df['memo_clean']\n",
    "y = df['category_description']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "e16e2f118d4d4f7d90b764b45ddfb5d1",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "c4d250fa493f4e20bcd4db999547dab4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "X_train_encoded = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
    "X_val_encoded = tokenizer(X_val.tolist(), truncation=True, padding=True)\n",
    "X_test_encoded = tokenizer(X_test.tolist(), truncation=True, padding=True)\n",
    "\n",
    "label_to_id = {label: idx for idx, label in enumerate(sorted(set(y)))}\n",
    "y_train_numeric = [label_to_id[label] for label in y_train]\n",
    "y_val_numeric = [label_to_id[label] for label in y_val]\n",
    "y_test_numeric = [label_to_id[label] for label in y_test]\n",
    "\n",
    "# Convert the numeric labels to a tensor\n",
    "y_train_tensor = torch.tensor(y_train_numeric)\n",
    "\n",
    "class MemoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "# Create a dataset\n",
    "train_dataset = MemoDataset(X_train_encoded, y_train_numeric)\n",
    "val_dataset = MemoDataset(X_val_encoded, y_val_numeric)\n",
    "test_dataset = MemoDataset(X_test_encoded, y_test_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9873db01a8554891b6c9d0d5912a4be5",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We convert the categorical data into numeric so it's ready to be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "682ec2057e0a46009fb8219d23aa4d81",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': 0,\n",
       " 'FOOD_AND_BEVERAGES': 1,\n",
       " 'GENERAL_MERCHANDISE': 2,\n",
       " 'GROCERIES': 3,\n",
       " 'MORTGAGE': 4,\n",
       " 'OVERDRAFT': 5,\n",
       " 'PETS': 6,\n",
       " 'RENT': 7,\n",
       " 'TRAVEL': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "70f45aa10be840ed99a48f6062bb43a5",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model',\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy='epoch',\n",
    "#     evaluation_strategy='steps',\n",
    "#     eval_steps=50,\n",
    "#     logging_steps=50,\n",
    ")\n",
    "\n",
    "# Adjust the Trainer (same as before)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "edbf26bab6af43bf81517f918c58d90c",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fine tune and save our model. This may take a while if not using a GPU, so if you have downloaded the pretrained `./bank_transaction_model`, feel free to move to skip this section and move to **Model Evaluation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "75e27446faab4b00b04b51e7cf7bc2e9",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11250' max='11250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11250/11250 11:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.402600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.331100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.213800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.199400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11250, training_loss=0.23618417680528428, metrics={'train_runtime': 716.7076, 'train_samples_per_second': 125.574, 'train_steps_per_second': 15.697, 'total_flos': 1942621674840000.0, 'train_loss': 0.23618417680528428, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "350b982800c440639ccf812859d0c9bc",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2889961302280426, 'eval_runtime': 13.1271, 'eval_samples_per_second': 761.782, 'eval_steps_per_second': 95.223, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "8c37c70dbd4843d59f09cd71d3e2621c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model('./bank_transaction_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ae0603e01c9841d194465827a158bf9b",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c24c2f85f51442739786f8193aa4a2d2",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "We save the fine-tuned model so it's ready to be used for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "0855ca96d4be45a9b486da90f7655869",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained('./bank_transaction_model')\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run predictions on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "f9b897955a784ad7a7d4772d898aaa15",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "782ee8a4497b4fa599c9dfe171053171",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-1.3649408 ,  0.2511525 ,  6.5304484 , ..., -2.4363623 ,\n",
       "        -2.3003874 , -1.867918  ],\n",
       "       [-1.8531574 ,  9.03224   , -0.61177796, ..., -2.5696285 ,\n",
       "        -2.8026402 , -1.5367205 ],\n",
       "       [-2.004621  ,  9.03414   , -0.50371367, ..., -2.8041766 ,\n",
       "        -2.8890438 , -1.5023757 ],\n",
       "       ...,\n",
       "       [-1.9455248 ,  9.025847  , -0.51613456, ..., -2.782323  ,\n",
       "        -2.8183486 , -1.4846706 ],\n",
       "       [-2.180538  , -0.2927844 ,  9.481965  , ..., -2.608956  ,\n",
       "        -2.294376  , -1.3611125 ],\n",
       "       [-1.9396539 ,  9.02098   , -0.4382331 , ..., -2.8683412 ,\n",
       "        -2.8205342 , -1.4936892 ]], dtype=float32), label_ids=array([2, 1, 1, ..., 1, 2, 1]), metrics={'test_loss': 0.278065025806427, 'test_runtime': 16.1549, 'test_samples_per_second': 619.007, 'test_steps_per_second': 77.376})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "c3e61f804ea340a28969ef856ee7326d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "y_pred = pred.predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "a3e240cbd50d4f178e4422ec8950a516",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy rate \n",
    "(y_pred == y_test_numeric).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "97e1ac3adcd44eae9bd8012b175f8db6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "id_to_label = {val:key for key, val in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "782220268c294973866297979dcb9f32",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2, GENERAL_MERCHANDISE\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "memo_statement = \"Amazon\"\n",
    "input_data = tokenizer(memo_statement, padding=True, truncation=True, return_tensors='pt')\n",
    "output = model(**input_data)\n",
    "predicted_label = torch.argmax(output.logits).item()\n",
    "print(f\"Predicted Label: {predicted_label}, {id_to_label[predicted_label]}\")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b6127f96c7974cbab940ff6d8e06ec66",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
